{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Python - Advanced Data Wrangling With Pandas <a class=\"tocSkip\"></center>\n",
    "# <center>QTM 350: Data Science Computing <a class=\"tocSkip\"></center>    \n",
    "# <center>Davi Moreira <a class=\"tocSkip\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Manipulate strings in Pandas by accessing methods from the `Series.str` attribute.\n",
    "- Understand how to use regular expressions in Pandas for wrangling strings.\n",
    "- Differentiate between datetime object in Pandas such as `Timestamp`, `Timedelta`, `Period`, `DateOffset`.\n",
    "- Create these datetime objects with functions like `pd.Timestamp()`, `pd.Period()`, `pd.date_range()`, `pd.period_range()`.\n",
    "- Index a datetime index with partial string indexing.\n",
    "- Perform basic datetime operations like splitting a datetime into constituent parts (e.g., `year`, `weekday`, `second`, etc), apply offsets, change timezones, and resample with `.resample()`.\n",
    "- Make basic plots in Pandas by accessing the `.plot` attribute or importing functions from `pandas.plotting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "<hr>\n",
    "\n",
    "The material assumes no prior knowledge of Python. Experience with programming concepts or another programming language will help, but is not required to understand the material.\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/davi-moreira/2024S_dsc_emory_qtm_350/main/lecture_material/material-topic-03/img/py4ds.png\" width=\"200\"/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "This topic material is based on the [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) book and adapted for our purposes in the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working With Strings\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Working with text data is common in data science. Luckily, Pandas Series and Index objects are equipped with a set of string processing methods which we'll explore here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### String dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "String data is represented in pandas using the `object` dtype, which is a generic dtype for representing mixed data or data of unknown size. It would be better to have a dedicated dtype and Pandas has just introduced this: the `StringDtype`. `object` remains the default dtype for strings however, as Pandas looks to continue testing and improving the `string` dtype. You can read more about the `StringDtype` in the [Pandas documentation here](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#text-data-types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### String Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've seen how libraries like NumPy and Pandas can vectorise operations for increased speed and useability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is not the case for arrays of strings however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.array(['Davi', 'Gabriel', 'Juliana', 'Jin', 'Alice'])\n",
    "x.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead, you would have to operate on each string object one at a time, using a loop for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "[name.upper() for name in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But even this will fail if your array contains a missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.array(['Davi', 'Gabriel', None, 'Juliana', 'Jin', 'Alice'])\n",
    "[name.upper() for name in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas addresses both of these issues (vectorization and missing values) with its string methods. String methods can be accessed by the `.str` attribute of Pandas Series and Index objects. Pretty much all built-in string operations (`.upper()`, `.lower()`, `.split()`, etc) and more are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s.str.split(\"ff\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also operate on Index objects (i.e., index or column labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(5, 3),\n",
    "                  columns = ['Measured Feature', 'recorded feature', 'PredictedFeature'],\n",
    "                  index = [f\"ROW{_}\" for _ in range(5)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's clean up those labels by:\n",
    "1. Removing the word \"feature\" and \"Feature\"\n",
    "2. Lowercase the \"ROW\" and add an underscore between the digit and letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.capitalize().str.replace(\"feature\", \"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index = df.index.str.lower().str.replace(\"w\", \"w_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great that worked! There are so many string operations you can use in Pandas. Here's a full list of all the string methods available in Pandas that I pulled from the documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| Method                     | Description                                                                                                                       |\n",
    "| -------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `Series.str.cat`           | Concatenate strings                                                                                                               |\n",
    "| `Series.str.split`         | Split strings on delimiter                                                                                                        |\n",
    "| `Series.str.rsplit`        | Split strings on delimiter working from the end of the string                                                                     |\n",
    "| `Series.str.get`           | Index into each element (retrieve i-th element)                                                                                   |\n",
    "| `Series.str.join`          | Join strings in each element of the Series with passed separator                                                                  |\n",
    "| `Series.str.get_dummies`   | Split strings on the delimiter returning DataFrame of dummy variables                                                             |\n",
    "| `Series.str.contains`      | Return boolean array if each string contains pattern/regex                                                                        |\n",
    "| `Series.str.replace`       | Replace occurrences of pattern/regex/string with some other string or the return value of a callable given the occurrence         |\n",
    "| `Series.str.repeat`        | Duplicate values (`s.str.repeat(3)` equivalent to `x * 3`)                                                                        |\n",
    "| `Series.str.pad`           | \"Add whitespace to left, right, or both sides of strings\"                                                                         |\n",
    "| `Series.str.center`        | Equivalent to `str.center`                                                                                                        |\n",
    "| `Series.str.ljust`         | Equivalent to `str.ljust`                                                                                                         |\n",
    "| `Series.str.rjust`         | Equivalent to `str.rjust`                                                                                                         |\n",
    "| `Series.str.zfill`         | Equivalent to `str.zfill`                                                                                                         |\n",
    "| `Series.str.wrap`          | Split long strings into lines with length less than a given width                                                                 |\n",
    "| `Series.str.slice`         | Slice each string in the Series                                                                                                   |\n",
    "| `Series.str.slice_replace` | Replace slice in each string with passed value                                                                                    |\n",
    "| `Series.str.count`         | Count occurrences of pattern                                                                                                      |\n",
    "| `Series.str.startswith`    | Equivalent to `str.startswith(pat)` for each element                                                                              |\n",
    "| `Series.str.endswith`      | Equivalent to `str.endswith(pat)` for each element                                                                                |\n",
    "| `Series.str.findall`       | Compute list of all occurrences of pattern/regex for each string                                                                  |\n",
    "| `Series.str.match`         | \"Call `re.match` on each element, returning matched groups as list\"                                                               |\n",
    "| `Series.str.extract`       | \"Call `re.search` on each element, returning DataFrame with one row for each element and one column for each regex capture group\" |\n",
    "| `Series.str.extractall`    | \"Call `re.findall` on each element, returning DataFrame with one row for each match and one column for each regex capture group\"  |\n",
    "| `Series.str.len`           | Compute string lengths                                                                                                            |\n",
    "| `Series.str.strip`         | Equivalent to `str.strip`                                                                                                         |\n",
    "| `Series.str.rstrip`        | Equivalent to `str.rstrip`                                                                                                        |\n",
    "| `Series.str.lstrip`        | Equivalent to `str.lstrip`                                                                                                        |\n",
    "| `Series.str.partition`     | Equivalent to `str.partition`                                                                                                     |\n",
    "| `Series.str.rpartition`    | Equivalent to `str.rpartition`                                                                                                    |\n",
    "| `Series.str.lower`         | Equivalent to `str.lower`                                                                                                         |\n",
    "| `Series.str.casefold`      | Equivalent to `str.casefold`                                                                                                      |\n",
    "| `Series.str.upper`         | Equivalent to `str.upper`                                                                                                         |\n",
    "| `Series.str.find`          | Equivalent to `str.find`                                                                                                          |\n",
    "| `Series.str.rfind`         | Equivalent to `str.rfind`                                                                                                         |\n",
    "| `Series.str.index`         | Equivalent to `str.index`                                                                                                         |\n",
    "| `Series.str.rindex`        | Equivalent to `str.rindex`                                                                                                        |\n",
    "| `Series.str.capitalize`    | Equivalent to `str.capitalize`                                                                                                    |\n",
    "| `Series.str.swapcase`      | Equivalent to `str.swapcase`                                                                                                      |\n",
    "| `Series.str.normalize`     | Return Unicode normal form. Equivalent to `unicodedata.normalize`                                                                 |\n",
    "| `Series.str.translate`     | Equivalent to `str.translate`                                                                                                     |\n",
    "| `Series.str.isalnum`       | Equivalent to `str.isalnum`                                                                                                       |\n",
    "| `Series.str.isalpha`       | Equivalent to `str.isalpha`                                                                                                       |\n",
    "| `Series.str.isdigit`       | Equivalent to `str.isdigit`                                                                                                       |\n",
    "| `Series.str.isspace`       | Equivalent to `str.isspace`                                                                                                       |\n",
    "| `Series.str.islower`       | Equivalent to `str.islower`                                                                                                       |\n",
    "| `Series.str.isupper`       | Equivalent to `str.isupper`                                                                                                       |\n",
    "| `Series.str.istitle`       | Equivalent to `str.istitle`                                                                                                       |\n",
    "| `Series.str.isnumeric`     | Equivalent to `str.isnumeric`                                                                                                     |\n",
    "| `Series.str.isdecimal`     | Equivalent to `str.isdecimal`                                                                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I will also mention that I often use the dataframe method `df.replace()` to do string replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['replace me', 'b', 'c'],\n",
    "                   'col2': [1, 99999, 3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.replace({'replace me': 'a',\n",
    "            99999: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A regular expression (regex) is a sequence of characters that defines a search pattern. For more complex string operations, you'll definitely want to use regex. [Here's a great cheatsheet](https://www.rexegg.com/regex-quickstart.html) of regular expression syntax. You can also jump over to [RegExr.com](https://regexr.com/) and play around until you find the expression you want. Many Pandas string functions accept regular expressions as input, these are the most common ones:\n",
    "\n",
    "|Method|Description|\n",
    "|---|---|\n",
    "|`match()`|Call re.match() on each element, returning a boolean.\n",
    "|`extract()`|Call re.match() on each element, returning matched groups as strings.\n",
    "|`findall()`|Call re.findall() on each element\n",
    "|`replace()`|Replace occurrences of pattern with some other string\n",
    "|`contains()`|Call re.search() on each element, returning a boolean\n",
    "|`count()`|Count occurrences of pattern\n",
    "|`split()`|Equivalent to str.split(), but accepts regexps\n",
    "|`rsplit()`|Equivalent to str.rsplit(), but accepts regexps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, we can easily find all names in our Series that: i) Do not start with an uppercase vowel. ii) End with a character that is not a lowercase vowel. iii) Can have any characters or no character at all in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(['Davi', 'Gabriel', None, 'Juliana', 'Jin', 'Alice'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.str.findall(r'^[^AEIOU].*[^aeiou]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `r` in the code `s.str.findall(r'^[^AEIOU].*[^aeiou]$')` indicates that the string is a raw string in Python. When a string is prefixed with `r` or `R`, it tells Python to interpret the string literally, meaning that escape characters are not processed. This is particularly useful when writing regular expressions, which often contain backslashes that would otherwise need to be escaped. For example, in regular expressions, the backslash `\\` is used to escape special characters or to indicate a special sequence. If you were not using a raw string, you would need to use a double backslash `\\\\` to achieve the same result.\n",
    "\n",
    "The pattern provided here is `r'^[^AEIOU].*[^aeiou]$'`:\n",
    "\n",
    "- `^`: This asserts the position at the start of the string.\n",
    "- `[^AEIOU]`: This is a character class that matches any character that is not an uppercase vowel (A, E, I, O, U). The ^ inside the brackets negates the character class.\n",
    "- `.*`: The dot . matches any character (except for line terminators), and the asterisk * quantifies the dot to match zero or more times. Together, .* matches any sequence of characters.\n",
    "- `[^aeiou]$`: This is another character class similar to the first one, but it's at the end of the string due to the `$` anchor, and it matches any character that is not a lowercase vowel (a, e, i, o, u).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regex can do some truly magical things so keep it in mind when you're doing complicated text wrangling. Let's see one more example on the cycling dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could find all the comments that contains the string \"Rain\" or \"rain\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['Comments'].str.contains(r\"[Rr]ain\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we didn't want to include \"Raining\" or \"raining\", we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['Comments'].str.contains(r\"^[Rr]ain$\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can even split strings and separate them into new columns, for example, based on punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Comments'].str.split(r\"[.,!]\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "My point being here that you can pretty much do anything your heart desires!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working With Datetimes\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just like with strings, Pandas has extensive functionality for working with time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datetime dtype and Motivation for Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Python has built-in support for datetime format, that is, an object that contains time and date information, in the `datetime` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "date = datetime(year=2005, month=7, day=9, hour=13, minute=54)\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also parse directly from a string, see [format codes here](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "date = datetime.strptime(\"July 9 2005, 13:54\", \"%B %d %Y, %H:%M\")\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then extract specific information from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Year: {date.strftime('%Y')}\")\n",
    "print(f\"Month: {date.strftime('%B')}\")\n",
    "print(f\"Day: {date.strftime('%d')}\")\n",
    "print(f\"Day name: {date.strftime('%A')}\")\n",
    "print(f\"Day of year: {date.strftime('%j')}\")\n",
    "print(f\"Time of day: {date.strftime('%p')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And perform basic operations, like adding a week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "date + timedelta(days=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But as with strings, working with arrays of datetimes in Python can be difficult and inefficient. NumPy, therefore included a datetime object to work more effectively with dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dates = np.array([\"2020-07-09\", \"2020-08-10\"], dtype=\"datetime64\")\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can create arrays using other built-in functions like `np.arange()` too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dates = np.arange(\"2020-07\", \"2020-12\", dtype='datetime64[M]')\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can easily do operations on arrays of time. You can check out all the datetime units and their format in the documentation [here](https://numpy.org/doc/stable/reference/arrays.datetime.html#datetime-units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dates +  np.timedelta64(2, 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But while numpy helps bring datetimes into the array world, it's missing a lot of functionality that we would commonly want/need for wrangling tasks. This is where Pandas comes in. Pandas consolidates and extends functionality from the `datetime` module, `numpy`, and other libraries like `scikits.timeseries` into a single place. Pandas provides 4 key datetime objects which we'll explore:\n",
    "1. Timestamp (like np.datetime64)\n",
    "2. Timedelta (like np.timedelta64)\n",
    "3. Period (custom object for regular ranges of datetimes)\n",
    "4. DateOffset (custom object like timedelta but factoring in calendar rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating Datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most commonly you'll want to:\n",
    "1. Create a single point in time with `pd.Timestamp()`, e.g., `2005-07-09 00:00:00`\n",
    "2. Create a span of time with `pd.Period()`, e.g., `2020 Jan`\n",
    "3. Create an array of datetimes with `pd.date_range()` or `pd.period_range()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(pd.Timestamp('2005-07-09'))  # parsed from string\n",
    "print(pd.Timestamp(year=2005, month=7, day=9))  # pass data directly\n",
    "print(pd.Timestamp(datetime(year=2005, month=7, day=9)))  # from datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The above is a specific point in time. Below, we can use `pd.Period()` to specify a span of time (like a day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "span = pd.Period('2005-07-09')\n",
    "print(span)\n",
    "print(span.start_time)\n",
    "print(span.end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "point = pd.Timestamp('2005-07-09 12:00')\n",
    "span = pd.Period('2005-07-09')\n",
    "print(f\"Point: {point}\")\n",
    "print(f\" Span: {span}\")\n",
    "print(f\"Point in span? {span.start_time < point < span.end_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Often, you'll want to create arrays of datetimes, not just single values. Arrays of datetimes are of the class `DatetimeIndex`/`PeriodIndex`/`TimedeltaIndex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.date_range('2020-09-01 12:00',\n",
    "              '2020-09-11 12:00',\n",
    "              freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.period_range('2020-09-01',\n",
    "                '2020-09-11',\n",
    "                freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use `Timedelta` objects to perform temporal operations like adding or subtracting time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.date_range('2020-09-01 12:00', '2020-09-11 12:00', freq='D') + pd.Timedelta('1.5 hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, Pandas represents missing datetimes with `NaT`, which is just like `np.nan`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Timestamp(pd.NaT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### By converting existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's fairly common to have an array of dates as strings. We can use `pd.to_datetime()` to convert these to datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "string_dates = ['July 9, 2020', 'August 1, 2020', 'August 28, 2020']\n",
    "string_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(string_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more complex datetime format, use the `format` argument (see [Python Format Codes](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes) for help):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "string_dates = ['2020 9 July', '2020 1 August', '2020 28 August']\n",
    "pd.to_datetime(string_dates, format=\"%Y %d %B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or use a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dict_dates = pd.to_datetime({\"year\": [2020, 2020, 2020],\n",
    "                             \"month\": [7, 8, 8],\n",
    "                             \"day\": [9, 1, 28]})  # note this is a series, not an index!\n",
    "dict_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Index(dict_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### By reading directly from an external source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's practice by reading in our favourite cycling dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our index is just a plain old index at the moment, with dtype `object`, full of `string` dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.index.dtype)\n",
    "type(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could manually convert our index to a datetime using `pd.to_datetime()`. But even better, `pd.read_csv()` has an argument `parse_dates` which can do this automatically when reading the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.index.dtype)\n",
    "type(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `parse_dates` argument is very flexible and you can specify the datetime format for harder to read dates. There are other related arguments like `date_parser`, `dayfirst`, etc that are also helpful, check out the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Indexing Datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Datetime index objects are just like regular Index objects and can be selected, sliced, filtered, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can do partial string indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['2019-09']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exact matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['2019-10-10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['2019-10-10 13:47:14']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And slicing by ensuring that the DatetimeIndex of our DataFrame is sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "# print(df.index.min(), df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['2019-10-01':'2019-10-11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And for getting all results between two times of a day, use `df.between_time()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.between_time('00:00', '01:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Manipulating Datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can easily decompose our timeseries into its constituent components. There are [many attributes](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components) that define these constituents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As well as methods we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that if you're operating on a Series rather than a DatetimeIndex object, you can access this functionality through the `.dt` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "s = pd.Series(pd.date_range('2011-12-29', '2011-12-31'))\n",
    "s.year  # raises error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.dt.year  # works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Offsets and Timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We saw before how we can use `Timedelta` to add/subtract time to our datetimes. `Timedelta` respects absolute time, which can be problematic in some cases, where time is not regular. For example, on March 10, 2024, US daylight savings started and clocks **moved forward 1 hour**. This extra \"calendar hour\" is not accounted for in absolute time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t1 = pd.Timestamp('2024-03-09 12:00:00', tz='US/Eastern')\n",
    "t2 = t1 + pd.Timedelta(\"1 day\")\n",
    "print(f\"Original time: {t1}\")\n",
    "print(f\" Plus one day: {t2}\")  # note that time has moved from 12:00 -> 13:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead, we'd need to use a `Dateoffset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "t3 = t1 + pd.DateOffset(days=1)\n",
    "print(f\"Original time: {t1}\")\n",
    "print(f\" Plus one day: {t3}\")  # note that time has stayed at 12:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can see that we started including timezone information above. By default, datetime objects are \"timezone unaware\". To associate times with a timezone, we can use the `tz` argument in construction, or we can use the `tz_localize()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"        No timezone: {pd.Timestamp('2024-03-09 12:00:00').tz}\")\n",
    "print(f\"             tz arg: {pd.Timestamp('2024-03-09 12:00:00', tz='US/Eastern').tz}\")\n",
    "print(f\".tz_localize method: {pd.Timestamp('2024-03-09 12:00:00').tz_localize('US/Eastern').tz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can convert between timezones using the `.tz_convert()` method. You might have noticed something funny about the times Tom have been riding to UBC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There's something wrong with the timezone in this dataset. He was using the `Strava` app to document the rides, it was recording in Canadian time but converting to Australia time. Let's go ahead and fix that up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index = df.index.tz_localize(\"Canada/Pacific\")  # first specify the current timezone\n",
    "df.index = df.index.tz_convert(\"Australia/Sydney\")  # then convert to the proper timezone\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could have also used a `DateOffset` if we knew the offset we wanted to apply, in this case, 7 hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0, parse_dates=True)\n",
    "df.index = df.index + pd.DateOffset(hours=-7)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Resampling and Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the most common operations you will want do when working with time series is resampling the time series to a coarser/finer/regular resolution. For example, you may want to resample daily data to weekly data. We can do that with the `.resample()` method. For example, let's resample the irregular cycling timeseries to a regular 12-hourly series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.resample(\"1D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`Resampler` objects are very similar to the `groupby` objects we saw in the previous topic. We need to apply an aggregating function on our grouped timeseries, just like we did with `groupby` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns before resampling\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "dfr = numeric_df.resample(\"1D\").mean()\n",
    "dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There's quite a few `NaN`s in there? Some days Tom didn't ride, but some might by weekends too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfr['Weekday'] = dfr.index.day_name()\n",
    "dfr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas support \"business time\" operations and format codes in all the timeseries functions we've seen so far. You can check out [the documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) for more info, but let's specify business days here to get rid of those weekends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "dfr = numeric_df.resample(\"1B\").mean() # \"B\" is business day\n",
    "dfr['Weekday'] = dfr.index.day_name()\n",
    "dfr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Hierachical Indexing\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hierachical indexing**, sometimes called \"multi-indexing\" or \"stacked indexing\", is how Pandas \"nests\" data. The idea is to facilitate the storage of high dimensional data in a 2D dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/davi-moreira/2024S_dsc_emory_qtm_350/main/lecture_material/material-topic-03/img/pandas_stacking.gif)\n",
    "\n",
    "Source: [Giphy](https://giphy.com/gifs/panda-playing-QoCoLo2opwUW4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a Hierachical Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's start with a motivating example. Say you want to track how many courses each Data Science instructor taught over the years in a Pandas Series.\n",
    "\n",
    "We could use a tuple to make an appropriate index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "index = [('Davi', 2019), ('Davi', 2020),\n",
    "         ('Gabriel', 2019), ('Gabriel', 2020),\n",
    "         ('Juliana', 2019), ('Juliana', 2020)]\n",
    "courses = [4, 6, 5, 5, 6, 3]\n",
    "s = pd.Series(courses, index)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can still kind of index this series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.loc[(\"Davi\", 2019):(\"Davi\", 2019)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But if we wanted to get all of the values for 2019, we'd need to do some messy looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s[[i for i in s.index if i[1] == 2019]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The better way to set up this problem is with a multi-index (\"hierachical index\"). We can create a multi-index with `pd.MultiIndex.from_tuple()`. There are [other variations](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.MultiIndex.html) of `.from_X` but tuple is most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mi = pd.MultiIndex.from_tuples(index)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(courses, mi)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can do more efficient and logical indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.loc['Davi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.loc[:, 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.loc[\"Davi\", 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could also create the index by passing iterables like a list of lists directly to the `index` argument, but it's not as explicit or intutitive as using `pd.MultIndex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "index = [['Davi', 'Davi', 'Gabriel', 'Gabriel', 'Juliana', 'Juliana'],\n",
    "         [2019, 2020, 2019, 2020, 2019, 2020]]\n",
    "courses = [4, 6, 5, 5, 6, 3]\n",
    "s = pd.Series(courses, index)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stacking / Unstacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You might have noticed that we could also represent our multi-index series as a dataframe. Pandas noticed this too and provides the `.stack()` and `.unstack()` methods for switching between dataframes and multi-index series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s = s.unstack()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using a Hierachical Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observing the multi-index <-> dataframe equivalence above, you might wonder why we would even want multi-indices. Above, we were only dealing with 2D data, but a multi-index allows us to store any arbitrary number of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "index = [['Davi', 'Davi', 'Gabriel', 'Gabriel', 'Juliana', 'Juliana'],\n",
    "         [2019, 2020, 2019, 2020, 2019, 2020]]\n",
    "courses = [4, 6, 5, 5, 6, 3]\n",
    "s = pd.Series(courses, index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(s).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s.loc['Davi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "davi = pd.DataFrame({\"Courses\": [4, 6],\n",
    "                    \"Students\": [273, 342]},\n",
    "                    index = [2019, 2020])\n",
    "gabriel = pd.DataFrame({\"Courses\": [5, 5],\n",
    "                     \"Students\": [293, 420]},\n",
    "                     index = [2019, 2020])\n",
    "juliana = pd.DataFrame({\"Courses\": [6, 3],\n",
    "                     \"Students\": [363, 190]},\n",
    "                     index = [2019, 2020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we have three 2D dataframes that we are going to join together. There are so many ways you can do this, but we will use `pd.concat()` and then specify the `keys` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3 = pd.concat((davi, gabriel, juliana),\n",
    "               keys= ['Davi', 'Gabriel', 'Juliana'],\n",
    "               axis=0)\n",
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we have 3 dimensions of information in a single structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.loc['Davi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.loc['Davi', 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access deeper levels in various ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.loc['Davi', 2019]['Courses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.loc[('Davi', 2019), 'Courses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we name our index columns, we can also use `.query()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3 = s3.rename_axis(index=[\"Name\", \"Year\"])\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.query(\"Year == 2019\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or you might prefer the \"stacked\" version of our hierachical index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.stack().loc[('Davi', 2019, 'Courses')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By the way, we can also use all the previous methods we've learned about on hierachical dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.sort_values(by='Students')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There's one important exception! We can now specify a `level` argument to chose which level of our multi-index to apply the function to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s3.groupby(level='Year').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing DataFrames\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pandas provides a `.plot()` method on Series and DataFrames which we will see briefly here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Simple Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cycling_data.csv', index_col=0, parse_dates=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's go ahead and make a plot of the distances Tom have ridden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Distance'].plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cumulative distance might be more informative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Distance'].cumsum().plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many configuration options for these plots which build of the `matplotlib` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Distance'].cumsum().plot.line(fontsize=14, linewidth = 2, color = 'r', ylabel=\"km\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is possible to use built-in themes which do a lot of the colour and text formatting for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 16,\n",
    "                     'axes.labelweight': 'bold',\n",
    "                     'figure.figsize': (8,6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['Distance'].dropna().cumsum().plot.line(ylabel=\"km\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some people have also made custom themes, like this fun [cyberpunk theme](https://github.com/dhaitz/mplcyberpunk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplcyberpunk\n",
    "plt.style.use(\"cyberpunk\")\n",
    "\n",
    "df['Distance'].plot.line(ylabel=\"km\")\n",
    "mplcyberpunk.add_glow_effects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many other kinds of plots you can make too:\n",
    "\n",
    "|Method|Plot Type|\n",
    "|---|---|\n",
    "|`bar` or `barh` | bar plots|\n",
    "|`hist` | histogram|\n",
    "|`box` | boxplot|\n",
    "|`kde` or `density` | density plots|\n",
    "|`area` | area plots|\n",
    "|`scatter` | scatter plots|\n",
    "|`hexbin` | hexagonal bin plots|\n",
    "|`pie` | pie plots|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 16,\n",
    "                     'axes.labelweight': 'bold',\n",
    "                     'figure.figsize': (8,6)})\n",
    "df['Distance'].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['Distance'].plot.density();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pandas Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pandas also supports a few more advanced plotting functions in the `pandas.plotting` module. You can view them in the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#plotting-tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scatter_matrix(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have an outlier time in the data above, a time value of ~48,000. Let's remove it and re-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scatter_matrix(df.query('Time < 4000'), alpha=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 'Pandas' (`ydata`) Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pandas profiling is a nifty tool for generating summary reports and doing exploratory data analysis on dataframes. [Pandas profiling](https://github.com/pandas-profiling/pandas-profiling) is not part of base Pandas and it is changing its name to [`ydata-profiling`](https://pypi.org/project/pandas-profiling/). \n",
    "To run this section code I highly recommend you to use [Google Colab](https://colab.google/). You can also install the package in your machine with:\n",
    " \n",
    "```\n",
    "$ conda install -c conda-forge ydata-profiling\n",
    "```\n",
    "\n",
    "In Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cycling_data.csv') # make sure the dataset is with the notebook in the root of you directory.\n",
    "df.profile_report(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook _09-py-wrangling-advanced.ipynb to html\n",
      "[NbConvertApp] Writing 408719 bytes to 09-py-wrangling-advanced.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert _09-py-wrangling-advanced.ipynb --to html --template classic --output 09-py-wrangling-advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Thank you!<a class=\"tocSkip\"></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Lecture Outline",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "46.8229px",
    "left": "24.9983px",
    "top": "477.101px",
    "width": "158.429px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
